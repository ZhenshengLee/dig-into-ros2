# [Rationale](https://ros.org/reps/rep-0104.html#id48)

## [Why Include Operational Parameters](https://ros.org/reps/rep-0104.html#id49)

In defining CameraInfo, we have included both calibration parameters (fixed until the next calibration) and operational parameters (set by the camera driver, may change freely). The [Use Cases](https://ros.org/reps/rep-0104.html#use-cases) section demonstrates how the operational parameters can be used to describe a variety of useful capture modes without recalibrating.

One could ask, however, why include the operational parameters in CameraInfo at all? Binning rescales the focal lengths and principal point. The ROI offset shifts the principal point. A major alternative approach is to modify the projection matrix in the camera driver to describe the geometry of the individual output image. We have three objections to this approach.

First is separation of concerns. In ROS we consider camera drivers to have a very specific function: read pixels off the imager, shove them directly into a sensor_msgs/Image message, and publish. They are not expected to understand the camera model at all, merely regurgitate the calibration parameters provided to them externally. This keeps drivers simple and focused, and avoids requiring external dependencies such as OpenCV.

Second, the operational parameters are useful information in certain vision tasks, particularly ones which actively interact with the camera. The initial motivation for including ROI in CameraInfo was an application which tracked a small object at high speed by updating the ROI of a high-definition camera after each detection [[9]](https://ros.org/reps/rep-0104.html#milestone2). In this case, we needed to know the ROI of the incoming image to calculate the updated ROI.

Third, CameraInfo as specified permits some convenient optimizations. Without getting deeply into implementation details, rectifying a full resolution image for the first time is a fairly heavyweight operation. It involves generating matrices mapping each rectified pixel to a location in the raw image. These maps can be reused, however, on subsequent images, greatly reducing the expense of rectification. Furthermore, when ROI is used you can cheaply extract and use the same ROI from the full resolution map; this is a nice win when the ROI is frequently changing, as in the tracking application mentioned above. With the alternate approach, changing the ROI likely entails generating a new map specific to that ROI.

## [Unbinned Coordinates for ROI](https://ros.org/reps/rep-0104.html#id50)

The original draft of this REP expressed ROI in binned coordinates with the theory that this is slightly more intuitive to the user. One problem is that binned coordinates are less expressive than the full resolution coordinates; they do not allow bins that start at coordinates that are not multiples of the binning factor. Another advantage of using unbinned coordinates is that the ROI represents the same field of view regardless of the binning settings.

The IIDC (DCAM) 1394 specification [[10]](https://ros.org/reps/rep-0104.html#iidc1394) uses unbinned coordinates and explicitly does allow "off-grid" ROIs in Format_7 (Partial Image Size Format) modes. In contrast, the GenICam Standard Features Naming Convention [[11]](https://ros.org/reps/rep-0104.html#genicam) uses binned coordinates for ROI. Thus there is some disagreement among standards, but in the absence of any strong argument for using binned coordinates we opt for the technical advantages of unbinned coordinates.

## [Rejected Features](https://ros.org/reps/rep-0104.html#id51)

Some requested features are not included in this REP, generally because we do not see enough benefit to justify the added complexity.

### [Different Dimensions for Rectified Image](https://ros.org/reps/rep-0104.html#id52)

At least one user has wanted to make the dimensions of the rectified image larger than those of the raw image [[12]](https://ros.org/reps/rep-0104.html#resize). The advantage is that the rectified image can contain all of the pixels from the raw image without under-sampling them. When packing all of the original pixels into a rectified image with the same dimensions, some details can be lost, especially when there is significant radial distortion.

Implementation-wise, this is not particularly difficult. It requires adding fields to CameraInfo for the dimensions of the rectified image at full resolution, analogous to height and width. image_geometry would use these fields when creating the rectification maps. We would add some way to select different dimensions in [camera_calibration](http://www.ros.org/wiki/camera_calibration) [[16]](https://ros.org/reps/rep-0104.html#id25).

While potentially nice to have, we need more convincing that this feature is actually necessary. camera_calibration's alpha slider [[13]](https://ros.org/reps/rep-0104.html#calibtut) already allows the user to choose a trade-off between using all of the original pixels and preserving detail. The cost of adding this feature is some measure of additional complexity, and it is likely to cause confusion. It might break code that assumes the rectified image has the same dimensions as the raw image at full resolution.

Finally, if truly needed, this behavior could be implemented as a node publishing the enlarged and rectified image and a tweaked CameraInfo to a separate namespace. This solution loses the ability to unrectify points back to the original image resolution, but this a minor drawback.

### [Publish CameraInfo Only When Parameters Change](https://ros.org/reps/rep-0104.html#id53)

One FAQ is, "Why send CameraInfo with every Image message? Why not only once?" The main answer is that operational parameters (binning, ROI) may change, perhaps rapidly, from image to image. Even the calibration parameters may be updated regularly in self-calibrating systems.

The natural follow-up question is, "Why not send CameraInfo only when it changes?" The biggest issue is that when the CameraInfo does change, how do you synchronize that change with the Image stream on the client side? Either you go ahead with the most recent parameters, risking garbage interpretation if the new CameraInfo has not arrived yet, or you wait for a CameraInfo that most of the time will not be sent. Worst of all, what if a CameraInfo update gets dropped? In any case, the potential savings are meager, as CameraInfo is much smaller than the typical Image message.

To be fair, this question most recently came up in the context of a camera with a proprietary (and large) distortion model [[5]](https://ros.org/reps/rep-0104.html#bumblebee). Including this model in every CameraInfo message would indeed waste a large amount of bandwidth. Obviously, though, we can't support this proprietary model, and the thread suggested good alternative solutions. As long as CameraInfo remains small relative to an Image, we see no reason to complicate matters in pursuit of tiny bandwidth optimizations.

### [Mirroring](https://ros.org/reps/rep-0104.html#id54)

Some cameras [[8]](https://ros.org/reps/rep-0104.html#wge100) support effects such as flipping the image horizontally or vertically, or rotating the entire image 180 degrees. With flags for these settings in CameraInfo, it would be possible to update the calibration parameters with respect to the mirroring. However, this adds complexity in support of a relatively rare feature, and we do not see a compelling use case for changing the mirroring settings after calibrating the camera. The user should look at the raw images, mirror them into the desired orientation, and then consider those settings fixed prior to calibration.

### [Other Camera Settings](https://ros.org/reps/rep-0104.html#id55)

Other settings came up in discussion such as exposure, gain, white balance, color calibration, etc. However these settings are highly camera-dependent, and requiring drivers to convert camera-specific values into some canonical representation would be a significant burden. Furthermore, the main purpose of CameraInfo is to describe the geometry of the captured image, which is not affected by settings such as exposure.

Information such as color calibration could certainly be useful to post-processing nodes, but these settings could just as well be published on some other dedicated topic rather than including them in CameraInfo.

### [Focus and Zoom](https://ros.org/reps/rep-0104.html#id56)

Some cameras support auto-focus, or allow users to set focus/zoom programmatically. These settings do change the optics of the camera, and thus the geometry of the image. Unfortunately, describing the camera parameters as a function of focus is not a simple arithmetic operation as it is with binning or ROI. As far as we are aware, calibrating for focus and zoom is still an open research area with no firmly established solution. It's also unclear how to define focus in a camera-independent way.

For now, camera drivers that expose focus and zoom capabilities will have to be "smarter" than the typical driver and update the camera parameters themselves. Such a driver might store multiple calibrations for different focus settings, or use some more sophisticated model to interpolate the camera parameters to the current focus.

### [Multiple Distortion Models](https://ros.org/reps/rep-0104.html#id57)

Storing multiple distortion models in CameraInfo was suggested, so that code not supporting some new distortion model could fall back to a simpler one such as "plumb_bob". But there are other, simpler solutions to this problem, such as requiring users to upgrade their code (or else calibrate the camera themselves), or shipping multiple calibration files and allowing the user to select one compatible with his system.
